{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bullet Forge Training Data\n",
    "\n",
    "This notebook is used for forming the JSONL files used by `fine-tune.ipynb` to fine-tune the base model. The goal is to use `bullet-scraper.py` to scrape for open-source bullets at a particular URL and use those as completions. Then, those completions have prompts that are a combination of ChatGPT generated long-form paragraphs from those bullets, prepended with the bullet formatting prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run the Bullet Scraper\n",
    "\n",
    "Please see the `scraper/` directory for more details.\n",
    "\n",
    "The block below runs the scraper on all the websites located within the `scraper/websites.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths=[]\n",
    "\n",
    "with open('scraper/websites.txt', 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "for url in urls:\n",
    "    url = url.strip()\n",
    "    filename = url[url.index(\"www.\") + 4:url.index(\".com\")]\n",
    "    filepath = f\"data/raw/{filename}.txt\"\n",
    "    !python3 scraper/bullet_scraper.py \"{url}\" \"{filepath}\"\n",
    "    file_paths.append(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below allows you to run the scraper on other websites individually. It requires the following input:\n",
    "- BASE_URL: The base URL including the protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = input(\"Enter a base url to scrape from: \")\n",
    "\n",
    "filename = BASE_URL[BASE_URL.index(\"www.\") + 4:BASE_URL.index(\".com\")]\n",
    "filepath = f\"data/raw/{filename}.txt\"\n",
    "!python3 scraper/bullet_scraper.py \"{BASE_URL}\" \"{filepath}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Consolidate Scraped Data\n",
    "\n",
    "Consolidate all scraped bullet website outputs from the `data/raw` directory into one JSONL file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = \"data/raw/\"\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "file_paths_string = \" \".join(file_paths)\n",
    "\n",
    "\n",
    "!python3 scraper/cleanup.py {file_paths_string}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
