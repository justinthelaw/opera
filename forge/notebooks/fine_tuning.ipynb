{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bullet Forge Model Fine Tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Instantiate Global Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Max length of tokens a user may enter for summarization\n",
        "# Increasing this beyond 512 may increase compute time significantly\n",
        "max_input_token_length = 512\n",
        "# Max length of tokens the model should output for the summary\n",
        "# Approximately the number of tokens it may take to generate a bullet\n",
        "max_output_token_length = 35\n",
        "# Beams to use for beam search algorithm\n",
        "# Increased beams means increased quality, but increased compute time\n",
        "number_of_beams = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Fine Tune Checkpoint Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wB441x104K-o"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2023-07-15 23:30:11.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m275\u001b[0m - \u001b[1mLoading t5-large...\u001b[0m\n",
            "\u001b[32m2023-07-15 23:30:22.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m286\u001b[0m - \u001b[1mReading data...\u001b[0m\n",
            "\u001b[32m2023-07-15 23:30:22.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m298\u001b[0m - \u001b[1mFULL Dataset: (450, 2)\u001b[0m\n",
            "\u001b[32m2023-07-15 23:30:22.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m299\u001b[0m - \u001b[1mTRAIN Dataset: (360, 2)\u001b[0m\n",
            "\u001b[32m2023-07-15 23:30:22.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mVALIDATION Dataset: (90, 2)\u001b[0m\n",
            "\u001b[32m2023-07-15 23:30:22.930\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mInitiating fine tuning...\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=&lt;AddBackward0&gt;) |\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=<AddBackward0>) |\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=&lt;AddBackward0&gt;) |\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=<AddBackward0>) |\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=&lt;AddBackward0&gt;) |\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=<AddBackward0>) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=<AddBackward0>) |\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=&lt;AddBackward0&gt;) |\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=<AddBackward0>) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=<AddBackward0>) |\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(3.1788, grad_fn=&lt;AddBackward0&gt;) |\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=<AddBackward0>) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(3.1788, grad_fn=<AddBackward0>) |\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(3.1788, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(1.1532, grad_fn=&lt;AddBackward0&gt;) |\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=<AddBackward0>) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(3.1788, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(1.1532, grad_fn=<AddBackward0>) |\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(3.1788, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(1.1532, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(3.1195, grad_fn=&lt;AddBackward0&gt;) |\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=<AddBackward0>) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(3.1788, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(1.1532, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(3.1195, grad_fn=<AddBackward0>) |\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                     Training Status                     </span>\n",
              "+-------------------------------------------------------+\n",
              "|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                  Loss                  </span>|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=&lt;AddBackward0&gt;) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=&lt;AddBackward0&gt;)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  4   |  10   | tensor(3.1788, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |   0   | tensor(1.1532, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  5   |  10   | tensor(3.1195, grad_fn=&lt;AddBackward0&gt;) |\n",
              "|  6   |   0   | tensor(1.0758, grad_fn=&lt;AddBackward0&gt;) |\n",
              "+-------------------------------------------------------+\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                     Training Status                     \u001b[0m\n",
              "+-------------------------------------------------------+\n",
              "|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                 Loss                  \u001b[0m|\n",
              "|------+-------+----------------------------------------|\n",
              "|  1   |   0   | tensor(32.1623, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(6.0856, grad_fn=<AddBackward0>) |\n",
              "|  1   |  20   | tensor(5.5537, grad_fn=<AddBackward0>) |\n",
              "|  2   |   0   | tensor(7.5343, grad_fn=<AddBackward0>) |\n",
              "|  2   |  10   | tensor(6.2988, grad_fn=<AddBackward0>) |\n",
              "|  2   |  20   | tensor(6.0131, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(13.7477, grad_fn=<AddBackward0>)|\n",
              "|  3   |  10   | tensor(10.7223, grad_fn=<AddBackward0>)|\n",
              "|  3   |  20   | tensor(8.3484, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(8.9654, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(7.7426, grad_fn=<AddBackward0>) |\n",
              "|  4   |  20   | tensor(4.7016, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(5.5619, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(5.6811, grad_fn=<AddBackward0>) |\n",
              "|  5   |  20   | tensor(12.4023, grad_fn=<AddBackward0>)|\n",
              "|  6   |   0   | tensor(6.8759, grad_fn=<AddBackward0>) |\n",
              "|  6   |  10   | tensor(12.1846, grad_fn=<AddBackward0>)|\n",
              "|  6   |  20   | tensor(10.0798, grad_fn=<AddBackward0>)|\n",
              "|  7   |   0   | tensor(11.6262, grad_fn=<AddBackward0>)|\n",
              "|  7   |  10   | tensor(9.7450, grad_fn=<AddBackward0>) |\n",
              "|  7   |  20   | tensor(7.6934, grad_fn=<AddBackward0>) |\n",
              "|  8   |   0   | tensor(6.1358, grad_fn=<AddBackward0>) |\n",
              "|  8   |  10   | tensor(7.5864, grad_fn=<AddBackward0>) |\n",
              "|  8   |  20   | tensor(2.1700, grad_fn=<AddBackward0>) |\n",
              "|  9   |   0   | tensor(8.1567, grad_fn=<AddBackward0>) |\n",
              "|  9   |  10   | tensor(3.2303, grad_fn=<AddBackward0>) |\n",
              "|  9   |  20   | tensor(5.9111, grad_fn=<AddBackward0>) |\n",
              "| 10   |   0   | tensor(9.9356, grad_fn=<AddBackward0>) |\n",
              "| 10   |  10   | tensor(5.1729, grad_fn=<AddBackward0>) |\n",
              "| 10   |  20   | tensor(6.7947, grad_fn=<AddBackward0>) |\n",
              "| 11   |   0   | tensor(7.9997, grad_fn=<AddBackward0>) |\n",
              "| 11   |  10   | tensor(3.6585, grad_fn=<AddBackward0>) |\n",
              "| 11   |  20   | tensor(5.1835, grad_fn=<AddBackward0>) |\n",
              "| 12   |   0   | tensor(3.5284, grad_fn=<AddBackward0>) |\n",
              "| 12   |  10   | tensor(6.6684, grad_fn=<AddBackward0>) |\n",
              "| 12   |  20   | tensor(5.5951, grad_fn=<AddBackward0>) |\n",
              "| 13   |   0   | tensor(6.6966, grad_fn=<AddBackward0>) |\n",
              "| 13   |  10   | tensor(2.5137, grad_fn=<AddBackward0>) |\n",
              "| 13   |  20   | tensor(7.5238, grad_fn=<AddBackward0>) |\n",
              "| 14   |   0   | tensor(3.4581, grad_fn=<AddBackward0>) |\n",
              "| 14   |  10   | tensor(9.3945, grad_fn=<AddBackward0>) |\n",
              "| 14   |  20   | tensor(7.4712, grad_fn=<AddBackward0>) |\n",
              "| 15   |   0   | tensor(7.3581, grad_fn=<AddBackward0>) |\n",
              "| 15   |  10   | tensor(2.2439, grad_fn=<AddBackward0>) |\n",
              "| 15   |  20   | tensor(3.2466, grad_fn=<AddBackward0>) |\n",
              "| 16   |   0   | tensor(3.2528, grad_fn=<AddBackward0>) |\n",
              "| 16   |  10   | tensor(1.0546, grad_fn=<AddBackward0>) |\n",
              "| 16   |  20   | tensor(6.2260, grad_fn=<AddBackward0>) |\n",
              "|  1   |   0   | tensor(19.9717, grad_fn=<AddBackward0>)|\n",
              "|  1   |  10   | tensor(17.4916, grad_fn=<AddBackward0>)|\n",
              "|  2   |   0   | tensor(11.9839, grad_fn=<AddBackward0>)|\n",
              "|  2   |  10   | tensor(8.9112, grad_fn=<AddBackward0>) |\n",
              "|  3   |   0   | tensor(4.4533, grad_fn=<AddBackward0>) |\n",
              "|  3   |  10   | tensor(2.5062, grad_fn=<AddBackward0>) |\n",
              "|  4   |   0   | tensor(2.2845, grad_fn=<AddBackward0>) |\n",
              "|  4   |  10   | tensor(3.1788, grad_fn=<AddBackward0>) |\n",
              "|  5   |   0   | tensor(1.1532, grad_fn=<AddBackward0>) |\n",
              "|  5   |  10   | tensor(3.1195, grad_fn=<AddBackward0>) |\n",
              "|  6   |   0   | tensor(1.0758, grad_fn=<AddBackward0>) |\n",
              "+-------------------------------------------------------+\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Fine Tuning Scripts\n",
        "import os\n",
        "import sys\n",
        "import signal\n",
        "import re\n",
        "from loguru import logger\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from rouge_score import rouge_scorer\n",
        "from transformers import (\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "from scripts.files import load_jsonl_data\n",
        "from scripts.bullet_patterns import *\n",
        "from scripts.rich_logger import *\n",
        "\n",
        "\n",
        "input_model = input(\n",
        "    \"What is the target model's relative directory path or checkpoint name on Hugging Face?\"\n",
        ")\n",
        "\n",
        "# Model fine tuning parameter control object\n",
        "model_params = {\n",
        "    # Name of the pre-trained model or checkpoint name that will be fine-tuned\n",
        "    \"MODEL\": f\"{input_model}\",\n",
        "    # Number of examples per batch during training\n",
        "    # Larger batch sizes require more memory, but can speed up training\n",
        "    \"TRAIN_BATCH_SIZE\": 32,\n",
        "    # Number of examples per batch during validation\n",
        "    # Larger batch sizes require more memory, but can speed up the validation process\n",
        "    \"VALID_BATCH_SIZE\": 32,\n",
        "    # Number of full passes through the entire training dataset\n",
        "    # More epochs can lead to better performance, but risk over-fitting\n",
        "    \"TRAIN_EPOCHS\": 16,\n",
        "    # Number of full passes through the entire validation dataset\n",
        "    # Typically kept to a single epoch as the validation set does not need to be repeatedly passed\n",
        "    \"VAL_EPOCHS\": 1,\n",
        "    # Determines the step size during gradient descent\n",
        "    # Affects how quickly or slowly a model learns\n",
        "    # Too high can cause instability, too low can cause slow learning\n",
        "    \"LEARNING_RATE\": 1e-3,\n",
        "    # Maximum number of tokens from source text that model accepts\n",
        "    # Longer sequences will be truncated to this length\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\": max_input_token_length,\n",
        "    # Maximum number of tokens from target text that model generates\n",
        "    # Longer sequences will be truncated to this length\n",
        "    \"MAX_TARGET_TEXT_LENGTH\": max_output_token_length,\n",
        "    # Random seed to ensure reproducibility\n",
        "    # Using the same seed will yield the same model given the same data and training process\n",
        "    \"SEED\": 88,\n",
        "    # Number of alternative sequences generated at each step\n",
        "    # More beams improve results, but increase computation\n",
        "    \"NUM_BEAMS\": number_of_beams,\n",
        "    # Multiplier to penalize repeated n-grams\n",
        "    # Higher values discourage repetition in the generated text\n",
        "    \"REPETITION_PENALTY\": 3.0,\n",
        "    # Penalty applied for producing long sequences\n",
        "    # Higher values encourage longer sequences\n",
        "    \"LENGTH_PENALTY\": 1.0,\n",
        "    # The number of steps to take before the gradient is averaged and applied\n",
        "    # Helps in stabilizing training and requires less memory\n",
        "    \"GRADIENT_ACCUMULATION_STEPS\": 1,\n",
        "    # Weight decay introduced to the optimizer to prevent over-fitting\n",
        "    # Regularization strategy by adding a small penalty, typically the L2 norm of the weights\n",
        "    \"WEIGHT_DECAY\": 0.0,\n",
        "    # Small constant to prevent any division by zero in the implementation (Adam)\n",
        "    \"ADAM_EPSILON\": 1e-8,\n",
        "    # Number of steps for the warmup phase\n",
        "    # Helps in avoiding very high and undesirable values of gradients at the start of training\n",
        "    \"WARMUP_STEPS\": 2,\n",
        "}\n",
        "\n",
        "model_output_directory = \"../models/\" + input(\n",
        "    \"What name would you like to give the fine-tuned model?\"\n",
        ")\n",
        "\n",
        "# Load JSONLdata\n",
        "data = load_jsonl_data(\n",
        "    \"../data/training/training_validation_set.jsonl\",\n",
        "    BULLET_PROMPT_PREFIX,\n",
        "    isDataFrame=True,\n",
        ")\n",
        "\n",
        "# Set device to be used based on GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "logger.info(f\"Loading {model_params['MODEL']}...\")\n",
        "# Model is sent to device (GPU/TPU) for using the hardware\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "model = model.to(device)\n",
        "# Tokenzier for encoding the text\n",
        "tokenizer = T5Tokenizer.from_pretrained(\n",
        "    model_params[\"MODEL\"], model_max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"]\n",
        ")\n",
        "\n",
        "# Creating a custom dataset for reading the dataset and loading it into the dataloader\n",
        "# to pass it to the neural network for fine tuning the model\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, dataframe, tokenizer, source_len, target_len, source_text, target_text\n",
        "    ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = target_len\n",
        "        self.target_text = self.data[target_text]\n",
        "        self.source_text = self.data[source_text]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_text = str(self.source_text[index])\n",
        "        target_text = str(self.target_text[index])\n",
        "\n",
        "        # Cleaning data so as to ensure data is in string type\n",
        "        source_text = \" \".join(source_text.split())\n",
        "        target_text = \" \".join(target_text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus(\n",
        "            [source_text],\n",
        "            max_length=self.source_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        target = self.tokenizer.batch_encode_plus(\n",
        "            [target_text],\n",
        "            max_length=self.summ_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        source_ids = source[\"input_ids\"].squeeze()\n",
        "        source_mask = source[\"attention_mask\"].squeeze()\n",
        "        target_ids = target[\"input_ids\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
        "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
        "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
        "            \"target_ids_y\": target_ids.to(dtype=torch.long),\n",
        "        }\n",
        "\n",
        "\n",
        "# Generates a penalty for not complying to bullet formatting\n",
        "def format_penalty(outputs, tokenizer, format_pattern):\n",
        "    total_penalty = 0.0\n",
        "    logits = outputs.logits\n",
        "    # Converting the logits to token ids\n",
        "    token_ids = torch.argmax(logits, dim=-1)\n",
        "    # Decoding the token ids to text\n",
        "    decoded_outputs = [\n",
        "        tokenizer.decode(token_ids[i], skip_special_tokens=True)\n",
        "        for i in range(token_ids.shape[0])\n",
        "    ]\n",
        "\n",
        "    for text in decoded_outputs:\n",
        "        match = re.fullmatch(format_pattern, text)\n",
        "        # If the output does not match the desired format exactly, add a penalty\n",
        "        if not match:\n",
        "            total_penalty += 1.0\n",
        "\n",
        "    return torch.tensor(total_penalty, device=logits.device)\n",
        "\n",
        "\n",
        "# Function to be called for training with the parameters passed from main function\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer, scheduler):\n",
        "    model.train()\n",
        "    for step, data in enumerate(loader, 0):\n",
        "        y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
        "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=ids,\n",
        "            attention_mask=mask,\n",
        "            decoder_input_ids=y_ids,\n",
        "            labels=lm_labels,\n",
        "        )\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Add a penalty to the loss for outputs that don't match the format\n",
        "        format_loss = format_penalty(outputs, tokenizer, BULLET_PATTERN)\n",
        "        total_loss = loss + format_loss\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            training_logger.add_row(str(epoch + 1), str(step), str(total_loss))\n",
        "            general_logger.print(training_logger)\n",
        "\n",
        "        total_loss.backward()\n",
        "\n",
        "        # Perform a backward pass (back propagation)\n",
        "        if (step + 1) % model_params[\"GRADIENT_ACCUMULATION_STEPS\"] == 0:\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Adjust the learning rate based on the number of iterations\n",
        "            scheduler.step()\n",
        "        pass\n",
        "\n",
        "\n",
        "# Function to evaluate model for predictions and compute ROUGE scores\n",
        "def validate(tokenizer, model, device, loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    # Initialize the rouge scorer\n",
        "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "    scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
        "            ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
        "            mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=ids,\n",
        "                attention_mask=mask,\n",
        "                max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "                num_beams=model_params[\"NUM_BEAMS\"],\n",
        "                repetition_penalty=model_params[\"REPETITION_PENALTY\"],\n",
        "                length_penalty=model_params[\"LENGTH_PENALTY\"],\n",
        "                early_stopping=True,\n",
        "            )\n",
        "            preds = [\n",
        "                tokenizer.decode(\n",
        "                    g, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "                )\n",
        "                for g in generated_ids\n",
        "            ]\n",
        "            targets = [\n",
        "                tokenizer.decode(\n",
        "                    t, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "                )\n",
        "                for t in y\n",
        "            ]\n",
        "\n",
        "            # Calculate rouge scores for each prediction and corresponding target\n",
        "            for pred, target in zip(preds, targets):\n",
        "                score = scorer.score(target, pred)\n",
        "                scores.append(score)\n",
        "\n",
        "            if _ % 10 == 0:\n",
        "                general_logger.print(f\"Completed {_}\")\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(targets)\n",
        "\n",
        "    # Compute the average ROUGE scores for the entire validation set\n",
        "    avg_scores = {\n",
        "        \"rouge1\": np.mean([score[\"rouge1\"].fmeasure for score in scores]),\n",
        "        \"rouge2\": np.mean([score[\"rouge2\"].fmeasure for score in scores]),\n",
        "        \"rougeL\": np.mean([score[\"rougeL\"].fmeasure for score in scores]),\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Average ROUGE scores: {avg_scores}\")\n",
        "\n",
        "    return predictions, actuals\n",
        "\n",
        "\n",
        "# T5 training main function\n",
        "def T5Trainer(dataframe, source_text, target_text, model_params, output_dir):\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(model_params[\"SEED\"])\n",
        "    np.random.seed(model_params[\"SEED\"])\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    logger.info(f\"Reading data...\")\n",
        "    # Importing the raw dataset\n",
        "    dataframe = dataframe[[source_text, target_text]]\n",
        "\n",
        "    # Creation of Dataset and Dataloader\n",
        "    # 80% of the data will be used for training and the rest for validation\n",
        "    train_size = 0.8\n",
        "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\n",
        "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    logger.info(f\"FULL Dataset: {dataframe.shape}\")\n",
        "    logger.info(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
        "    logger.info(f\"VALIDATION Dataset: {val_dataset.shape}\")\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of data loader\n",
        "    training_set = CustomDataset(\n",
        "        train_dataset,\n",
        "        tokenizer,\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        source_text,\n",
        "        target_text,\n",
        "    )\n",
        "    val_set = CustomDataset(\n",
        "        val_dataset,\n",
        "        tokenizer,\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        source_text,\n",
        "        target_text,\n",
        "    )\n",
        "\n",
        "    # Defining the parameters for creation of data loaders\n",
        "    train_params = {\n",
        "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
        "        \"shuffle\": True,\n",
        "        \"num_workers\": 0,\n",
        "    }\n",
        "    val_params = {\n",
        "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
        "        \"shuffle\": False,\n",
        "        \"num_workers\": 0,\n",
        "    }\n",
        "\n",
        "    # Creation of data loaders for testing and validation - this will be used down for training and validation stage for the model\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        params=[p for p in model.parameters() if p.requires_grad],\n",
        "        lr=model_params[\"LEARNING_RATE\"],\n",
        "        eps=model_params[\"ADAM_EPSILON\"],\n",
        "        weight_decay=model_params[\"WEIGHT_DECAY\"],\n",
        "    )\n",
        "\n",
        "    # Define the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=model_params[\"WARMUP_STEPS\"],\n",
        "        num_training_steps=model_params[\"TRAIN_EPOCHS\"]\n",
        "        * len(training_loader)\n",
        "        // model_params[\"GRADIENT_ACCUMULATION_STEPS\"],\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    logger.info(f\"Initiating fine tuning...\")\n",
        "\n",
        "    for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
        "        train(epoch, tokenizer, model, device, training_loader, optimizer, scheduler)\n",
        "        pass\n",
        "\n",
        "    logger.info(f\"Saving model...\")\n",
        "    # Saving the model after training\n",
        "    model.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    # Evaluating validation dataset\n",
        "    logger.info(f\"Initiating validation...\")\n",
        "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
        "        predictions, actuals = validate(tokenizer, model, device, val_loader)\n",
        "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n",
        "        final_df.to_csv(os.path.join(output_dir, \"predictions.csv\"))\n",
        "\n",
        "    general_logger.save_text(os.path.join(output_dir, \"logs.txt\"))\n",
        "\n",
        "    logger.success(f\"Model validation completed!\")\n",
        "    logger.info(f\"Fine-tuned model saved to: {output_dir}\")\n",
        "    logger.info(\n",
        "        f\"Validation data saved to: {os.path.join(output_dir,'predictions.csv')}\"\n",
        "    )\n",
        "    logger.info(f\"Notebook logs saved to: {os.path.join(output_dir,'logs.txt')}\")\n",
        "\n",
        "# In case of interrupt, save model\n",
        "def save_and_exit(signal, frame):\n",
        "    logger.info(\"Saving model...\")\n",
        "    model.save_pretrained(model_output_directory)\n",
        "    tokenizer.save_pretrained(model_output_directory)\n",
        "    logger.success(\"Model saved. Shutting down...\")\n",
        "    sys.exit(0)  # Exit the process cleanly\n",
        "\n",
        "# Attach the SIGINT signal (generated by Ctrl+C) to the handler\n",
        "signal.signal(signal.SIGINT, save_and_exit)\n",
        "\n",
        "# Run training function on the T5 model using data set and training parameters\n",
        "T5Trainer(\n",
        "    dataframe=data,\n",
        "    source_text=\"input\",\n",
        "    target_text=\"output\",\n",
        "    model_params=model_params,\n",
        "    output_dir=f\"{model_output_directory}\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Fine Tuned Model Manual Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> INPUT TEXT: During a structure fire incident, I deployed a handline and effectively knocked down and extinguished a kitchen blaze. Through my prompt response and actions, I saved the dining facility, preventing an estimated $3.4 million in damages.\n",
            "\t> EXPECTED SUMMARY: - Deployed handline into structure fire; knocked down & extinguished kitchen blaze--saved $3.4M dining facility\n",
            "\t> GENERATE SUMMARY: - Structured building fire incident; deployed handlined kitchen blazed kitchen blazed kitchen blazed kitchen blazed kitchen blazed kitchen blaze\n",
            "\n",
            "> INPUT TEXT: As a team leader, I led a three-member team in addressing multiple engine discrepancies on E-8C aircraft. We successfully replaced 12 intake/exhaust rivets, resulting in a cost savings of $2.4 million by avoiding the need for complete engine replacements.\n",
            "\t> EXPECTED SUMMARY: - Led 3-member team on multiple E-8C engine discrepancies; replaced 12 intake/exhaust rivets--saved $2.4M replacement cost\n",
            "\t> GENERATE SUMMARY: - Team leader; led 3-member team leader/exhaust rivets on E-8C aircraft/exhaust rivets on E-8C aircraft/ex\n",
            "\n",
            "> INPUT TEXT: As a co-author, I contributed to the creation of a 64-page SABER Guide used for training Contracting Squadron (CONS) personnel. This guide streamlined training efforts, resulting in a savings of 120 manpower hours and was recognized as a strength during the Operational Readiness Inspection (ORI).\n",
            "\t> EXPECTED SUMMARY: - Co-authored 64 pg SABER Guide; used to train CONS personnel--120 mnhrs saved/identified as ORI Wing strength\n",
            "\t> GENERATE SUMMARY: - Co-author; created 64-page SABER Guided 120-page SABER Guided 60-page SABER Guided 60-page SABER Guided\n",
            "\n",
            "> INPUT TEXT: Through volunteering five hours of my time, I helped transport furniture to the operations building. I devised an efficient schedule to accommodate personnel, resulting in a cost savings of $1,000 for the squadron.\n",
            "\t> EXPECTED SUMMARY: - Volunteered 5 hours to transport furniture to ops building; devised schedule to accommodate personnel--saved squadron $1K\n",
            "\t> GENERATE SUMMARY: \n",
            "\n",
            "> INPUT TEXT: By acing two College-Level Examination Program (CLEP) tests, I earned six credit hours, saving the Air Force $1,500 in tuition assistance. Additionally, I am now 95% complete in earning my Community College of the Air Force (CCAF) degree in Aviation Operations.\n",
            "\t> EXPECTED SUMMARY: - Aced 2 CLEP tests; earned 6 credit hours--saved AF $1.5K in TA; CCAF degree in Aviation Ops 95% complete!\n",
            "\t> GENERATE SUMMARY: \n",
            "\n",
            "> INPUT TEXT: As the leader of the Premier training program, I successfully secured four classes for FY '19. This program was benchmarked during the '18 Unit Effectiveness Inspection (UEI) and was recognized as a 'Top Performer' by the Air Mobility Command (AMC) Inspector General (IG).\n",
            "\t> EXPECTED SUMMARY: - Led Premier training program; secured 4 FY '19 classes, benchmarked during '18 UEI--selected 'Top Performer' by AMC IG\n",
            "\t> GENERATE SUMMARY: - Leader of Premier training program; secured four classes for FY19\n",
            "\n",
            "> INPUT TEXT: By resolving delinquent Overseas Contingency Operations (OCO) Test, Measurement, and Diagnostic Equipment (TMDE) accounts, I scheduled 465 overdue items. This reallocation of parts in forward supply accounts improved Southwest Asia (SWA) equipment availability by up to 94%.\n",
            "\t> EXPECTED SUMMARY: - Resolved delinquent OCO TMDE accounts; scheduled 465 overdue items--SWA equipment availability up to 94%\n",
            "\t> GENERATE SUMMARY: \n",
            "\n",
            "> INPUT TEXT: Through providing elite Aircraft Rescue and Firefighting (ARFF) maintenance support, I successfully corrected 27 discrepancies. This ensured the readiness of 71 Mobile Emergency Centers (MECs) and enabled timely responses to two In-Flight Emergencies (IFE). My efforts were recognized by the Air Force District of Washington (AFDW) Command Chief Master Sergeant (CCM) with a commendation.\n",
            "\t> EXPECTED SUMMARY: - Provided elite ARFF maintenance support; corrected 27 discrepancies--enabled 71 MECs/2 IFE responses/coined by AFDW CCC\n",
            "\t> GENERATE SUMMARY: \n",
            "\n",
            "> INPUT TEXT: As the hand-picked Alternate COMSEC Manager, I demonstrated high motivation and readiness for a broader scope of responsibilities. My exceptional performance in this role makes me highly qualified for promotion to Staff Sergeant.\n",
            "\t> EXPECTED SUMMARY: - Hand-picked to be Alternate COMSEC Manager; highly motivated/ready for broader scope--must promote to SSgt!\n",
            "\t> GENERATE SUMMARY: - Hand-picked Alternate COMSEC Manager; hand-picked Alternate COMSEC Manager\n",
            "\n",
            "> INPUT TEXT: By resolving 120 ground radar Mission Impaired Capability Awaiting Parts (MICAPs), I successfully reallocated parts in forward supply accounts. This averted 4,900 MICAP hours and improved equipment availability for ground radar systems.\n",
            "\t> EXPECTED SUMMARY: - Resolved 120 ground radar MICAPs; reallocated parts in forward supply accounts--averted 4.9K MICAP hours\n",
            "\t> GENERATE SUMMARY: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Manual Test Scripts\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "from scripts.files import load_jsonl_data\n",
        "from scripts.bullet_patterns import BULLET_PROMPT_PREFIX\n",
        "\n",
        "input_model = input(\n",
        "    \"What is the target model's relative directory path or checkpoint name on Hugging Face?\"\n",
        ")\n",
        "\n",
        "# Model generation parameter control object\n",
        "model_params = {\n",
        "    # Name of the pre-trained model that will be fine-tuned\n",
        "    \"MODEL\": f\"{input_model}\",\n",
        "    # Maximum number of tokens from source text that model accepts\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\": max_input_token_length,\n",
        "    # Maximum number of tokens from target text that model generates\n",
        "    \"MAX_TARGET_TEXT_LENGTH\": max_output_token_length,\n",
        "    # Number of alternative sequences generated at each step\n",
        "    # More beams improve results, but increase computation\n",
        "    \"NUM_BEAMS\": number_of_beams,\n",
        "    # Scales logits before soft-max to control randomness\n",
        "    # Lower values (~0) make output more deterministic\n",
        "    \"TEMPERATURE\": 0.7,\n",
        "    # Limits generated tokens to top K probabilities\n",
        "    # Reduces chances of rare word predictions\n",
        "    \"TOP_K\": 50,\n",
        "    # Applies nucleus sampling, limiting token selection to a cumulative probability\n",
        "    # Creates a balance between randomness and determinism\n",
        "    \"TOP_P\": 0.95,\n",
        "}\n",
        "\n",
        "\n",
        "# Load the T5 model\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\n",
        "    model_params[\"MODEL\"], model_max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"]\n",
        ")\n",
        "\n",
        "# Load the data from the manual test file\n",
        "data = load_jsonl_data(\n",
        "    \"../data/training/manual_test_set.jsonl\", BULLET_PROMPT_PREFIX, isDataFrame=False\n",
        ")\n",
        "for line in data:\n",
        "    # Preprocess input\n",
        "    input_text = line[\"input\"]\n",
        "    expected_summary = line[\"output\"]\n",
        "\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        input_text, return_tensors=\"pt\", truncation=True, max_length=512\n",
        "    )\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        num_beams=model_params[\"NUM_BEAMS\"],\n",
        "        temperature=model_params[\"TEMPERATURE\"],\n",
        "        top_k=model_params[\"TOP_K\"],\n",
        "        top_p=model_params[\"TOP_P\"],\n",
        "        early_stopping=True,\n",
        "    )\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"> INPUT TEXT: {input_text}\")\n",
        "    print(f\"\\t> EXPECTED SUMMARY: {expected_summary}\")\n",
        "    print(f\"\\t> GENERATED SUMMARY: {summary}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM+sqU2Hgca8RM/Wjv+9kvQ",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "T5 Fine tuning with PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
