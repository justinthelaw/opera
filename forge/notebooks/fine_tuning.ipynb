{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bullet Forge Model Fine Tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Instantiate Global Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate global notebook params\n",
        "\n",
        "# Max length of tokens a user may enter for summarization\n",
        "# Increasing this beyond 512 may increase compute time significantly\n",
        "max_input_token_length = 1024\n",
        "# Max length of tokens the model should output for the summary\n",
        "# Approximately the number of tokens it may take to generate a bullet\n",
        "max_output_token_length = 40\n",
        "# Beams to use for beam search algorithm\n",
        "# Increased beams means increased quality, but increased compute time\n",
        "number_of_beams = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Fine Tune Checkpoint Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wB441x104K-o"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2023-07-16 15:34:42.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mLoading google/flan-t5-small...\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20fa49443749413ba60dcd8b5fed4a6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1ba1961a465452aa6160acf14e865a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at google/flan-t5-small were not used when initializing T5Model: ['lm_head.weight']\n",
            "- This IS expected if you are initializing T5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing T5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cccecbb95f00428f873e4ad6376bfd9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e20ec40c3db24468bbf9f4f2438774ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbb7bbf6c1814876a1be8039ed6bcac7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2023-07-16 15:34:51.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mReading data...\u001b[0m\n",
            "\u001b[32m2023-07-16 15:34:51.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mFULL Dataset: (460, 2)\u001b[0m\n",
            "\u001b[32m2023-07-16 15:34:51.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m290\u001b[0m - \u001b[1mTRAIN Dataset: (368, 2)\u001b[0m\n",
            "\u001b[32m2023-07-16 15:34:51.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m291\u001b[0m - \u001b[1mVALIDATION Dataset: (92, 2)\u001b[0m\n",
            "\u001b[32m2023-07-16 15:34:51.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mT5Trainer\u001b[0m:\u001b[36m345\u001b[0m - \u001b[1mInitiating fine tuning of google/flan-t5-small...\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "450db95231e244dfa47b794a331fc29c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "T5Model.forward() got an unexpected keyword argument 'labels'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 386\u001b[0m\n\u001b[1;32m    383\u001b[0m signal\u001b[39m.\u001b[39msignal(signal\u001b[39m.\u001b[39mSIGINT, save_and_exit)\n\u001b[1;32m    385\u001b[0m \u001b[39m# Run training function on the T5 model using data set and training parameters\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m T5Trainer(dataframe\u001b[39m=\u001b[39;49mdata, source_text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m, target_text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moutput\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "Cell \u001b[0;32mIn[3], line 349\u001b[0m, in \u001b[0;36mT5Trainer\u001b[0;34m(dataframe, source_text, target_text)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39mwith\u001b[39;00m refresher:\n\u001b[1;32m    348\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(model_params[\u001b[39m\"\u001b[39m\u001b[39mTRAIN_EPOCHS\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m--> 349\u001b[0m         train(\n\u001b[1;32m    350\u001b[0m             epoch, tokenizer, model, device, training_loader, optimizer, scheduler\n\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    352\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    354\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSaving fine-tuned  to \u001b[39m\u001b[39m{\u001b[39;00mmodel_output_directory\u001b[39m}\u001b[39;00m\u001b[39m ...\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[3], line 184\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, tokenizer, model, device, loader, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    181\u001b[0m ids \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39msource_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m    182\u001b[0m mask \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39msource_mask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m--> 184\u001b[0m outputs \u001b[39m=\u001b[39m model(\n\u001b[1;32m    185\u001b[0m     input_ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    186\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mmask,\n\u001b[1;32m    187\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49my_ids,\n\u001b[1;32m    188\u001b[0m     labels\u001b[39m=\u001b[39;49mlm_labels,\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m loss \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    192\u001b[0m \u001b[39m# Add a penalty to the loss for outputs that don't match the format\u001b[39;00m\n",
            "File \u001b[0;32m~/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[0;31mTypeError\u001b[0m: T5Model.forward() got an unexpected keyword argument 'labels'"
          ]
        }
      ],
      "source": [
        "# Fine tuning scripts\n",
        "import os\n",
        "import signal\n",
        "import re\n",
        "from loguru import logger\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "from rouge_score import rouge_scorer\n",
        "from transformers import (\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "from scripts.files import load_jsonl_data\n",
        "from scripts.bullet_patterns import *\n",
        "from scripts.rich_logger import training_table as table, live_refresher as refresher\n",
        "\n",
        "\n",
        "input_model = input(\n",
        "    \"What is the target model's relative directory path or checkpoint name on Hugging Face?\"\n",
        ")\n",
        "\n",
        "# Model fine tuning parameter control object\n",
        "model_params = {\n",
        "    # Name of the pre-trained model or checkpoint name that will be fine-tuned\n",
        "    \"MODEL\": f\"{input_model}\",\n",
        "    # Number of examples per batch during training\n",
        "    # Larger batch sizes require more memory, but can speed up training\n",
        "    \"TRAIN_BATCH_SIZE\": 32,\n",
        "    # Number of full passes through the entire training dataset\n",
        "    # More epochs can lead to better performance, but risk over-fitting\n",
        "    \"TRAIN_EPOCHS\": 8,\n",
        "    # Number of examples per batch during validation\n",
        "    # Larger batch sizes require more memory, but can speed up the validation process\n",
        "    \"VALID_BATCH_SIZE\": 1,\n",
        "    # Number of full passes through the entire validation dataset\n",
        "    # Typically kept to a single epoch as the validation set does not need to be repeatedly passed\n",
        "    \"VAL_EPOCHS\": 1,\n",
        "    # Affects how quickly or slowly a model learns\n",
        "    # Too high can cause instability, too low can cause slow learning\n",
        "    \"LEARNING_RATE\": 1e-4,\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\": max_input_token_length,\n",
        "    \"MAX_TARGET_TEXT_LENGTH\": max_output_token_length,\n",
        "    # Random seed to ensure reproducibility\n",
        "    # Using the same seed will yield the same model given the same data and training process\n",
        "    \"SEED\": 76,\n",
        "    \"NUM_BEAMS\": number_of_beams,\n",
        "    # Multiplier to penalize repeated n-grams\n",
        "    # Higher values discourage repetition in the generated text\n",
        "    \"REPETITION_PENALTY\": 1.0,\n",
        "    # Penalty applied for producing long sequences\n",
        "    # Higher values encourage longer sequences\n",
        "    \"LENGTH_PENALTY\": 1.0,\n",
        "    # The number of steps to take before the gradient is averaged and applied\n",
        "    # Helps in stabilizing training and requires less memory\n",
        "    \"GRADIENT_ACCUMULATION_STEPS\": 1,\n",
        "    # Weight decay introduced to the optimizer to prevent over-fitting\n",
        "    # Regularization strategy by adding a small penalty, typically the L2 norm of the weights\n",
        "    \"WEIGHT_DECAY\": 0.0,\n",
        "    # Small constant to prevent any division by zero in the implementation (Adam)\n",
        "    \"ADAM_EPSILON\": 1e-8,\n",
        "    # Number of steps for the warmup phase\n",
        "    # Helps in avoiding very high and undesirable values of gradients at the start of training\n",
        "    \"WARMUP_STEPS\": 3,\n",
        "    # The split between the training and validation data\n",
        "    \"TRAINING_VALIDATION_SPLIT\": 0.8,\n",
        "}\n",
        "\n",
        "model_output_directory = \"../models/\" + input(\n",
        "    \"What name would you like to give the fine-tuned model?\"\n",
        ")\n",
        "\n",
        "# Load JSONLdata\n",
        "data = load_jsonl_data(\n",
        "    \"../data/training/training_validation_set.jsonl\",\n",
        "    BULLET_PROMPT_PREFIX,\n",
        "    isDataFrame=True,\n",
        ")\n",
        "\n",
        "# Set device to be used based on GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "logger.info(f\"Loading {model_params['MODEL']}...\")\n",
        "# Model is sent to device (GPU/TPU) for using the hardware\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "model = model.to(device)\n",
        "# Tokenzier for encoding the text\n",
        "tokenizer = T5Tokenizer.from_pretrained(\n",
        "    model_params[\"MODEL\"], model_max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"]\n",
        ")\n",
        "\n",
        "\n",
        "# Creating a custom dataset for reading the dataset and loading it into the dataloader\n",
        "# to pass it to the neural network for fine tuning the model\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, dataframe, tokenizer, source_len, target_len, source_text, target_text\n",
        "    ):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = target_len\n",
        "        self.target_text = self.data[target_text]\n",
        "        self.source_text = self.data[source_text]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_text = str(self.source_text[index])\n",
        "        target_text = str(self.target_text[index])\n",
        "\n",
        "        # Cleaning data so as to ensure data is in string type\n",
        "        source_text = \" \".join(source_text.split())\n",
        "        target_text = \" \".join(target_text.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus(\n",
        "            [source_text],\n",
        "            max_length=self.source_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        target = self.tokenizer.batch_encode_plus(\n",
        "            [target_text],\n",
        "            max_length=self.summ_len,\n",
        "            pad_to_max_length=True,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        source_ids = source[\"input_ids\"].squeeze()\n",
        "        source_mask = source[\"attention_mask\"].squeeze()\n",
        "        target_ids = target[\"input_ids\"].squeeze()\n",
        "\n",
        "        return {\n",
        "            \"source_ids\": source_ids.to(dtype=torch.long),\n",
        "            \"source_mask\": source_mask.to(dtype=torch.long),\n",
        "            \"target_ids\": target_ids.to(dtype=torch.long),\n",
        "            \"target_ids_y\": target_ids.to(dtype=torch.long),\n",
        "        }\n",
        "\n",
        "\n",
        "# Generates a penalty for not complying to bullet formatting\n",
        "def format_penalty(outputs, tokenizer, format_pattern):\n",
        "    total_penalty = 0.0\n",
        "    logits = outputs.logits\n",
        "    # Converting the logits to token ids\n",
        "    token_ids = torch.argmax(logits, dim=-1)\n",
        "    # Decoding the token ids to text\n",
        "    decoded_outputs = [\n",
        "        tokenizer.decode(token_ids[i], skip_special_tokens=True)\n",
        "        for i in range(token_ids.shape[0])\n",
        "    ]\n",
        "\n",
        "    for text in decoded_outputs:\n",
        "        match = re.fullmatch(format_pattern, text)\n",
        "        # If the output does not match the desired format exactly, add a penalty\n",
        "        if not match:\n",
        "            total_penalty += 1.0\n",
        "\n",
        "    return torch.tensor(total_penalty, device=logits.device)\n",
        "\n",
        "\n",
        "# Function to be called for training with the parameters passed from main function\n",
        "def train(epoch, tokenizer, model, device, loader, optimizer, scheduler):\n",
        "    # Training logger refresh flag\n",
        "    table.switch_epoch_refresh()\n",
        "    # Stepping through training batches\n",
        "    for step, data in enumerate(loader, 0):\n",
        "        y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
        "        mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=ids,\n",
        "            attention_mask=mask,\n",
        "            decoder_input_ids=y_ids,\n",
        "            labels=lm_labels,\n",
        "        )\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Add a penalty to the loss for outputs that don't match the format\n",
        "        format_loss = format_penalty(outputs, tokenizer, BULLET_PATTERN)\n",
        "        total_loss = loss + format_loss\n",
        "\n",
        "        if table.get_epoch_refresh():\n",
        "            # Refresh table once per epoch\n",
        "            table.refresh_table(epoch, loss)\n",
        "\n",
        "        # Perform a backward pass (back propagation)\n",
        "        total_loss.backward()\n",
        "        if (step + 1) % model_params[\"GRADIENT_ACCUMULATION_STEPS\"] == 0:\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Adjust the learning rate based on the number of iterations\n",
        "            scheduler.step()\n",
        "        pass\n",
        "\n",
        "\n",
        "# Function to evaluate model for predictions and compute ROUGE scores\n",
        "def validate(tokenizer, model, device, loader):\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    # Initialize the rouge scorer\n",
        "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
        "    scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(loader, 0):\n",
        "            y = data[\"target_ids\"].to(device, dtype=torch.long)\n",
        "            ids = data[\"source_ids\"].to(device, dtype=torch.long)\n",
        "            mask = data[\"source_mask\"].to(device, dtype=torch.long)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=ids,\n",
        "                attention_mask=mask,\n",
        "                max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "                num_beams=model_params[\"NUM_BEAMS\"],\n",
        "                repetition_penalty=model_params[\"REPETITION_PENALTY\"],\n",
        "                length_penalty=model_params[\"LENGTH_PENALTY\"],\n",
        "                early_stopping=True,\n",
        "            )\n",
        "            preds = [\n",
        "                tokenizer.decode(\n",
        "                    g, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "                )\n",
        "                for g in generated_ids\n",
        "            ]\n",
        "            targets = [\n",
        "                tokenizer.decode(\n",
        "                    t, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "                )\n",
        "                for t in y\n",
        "            ]\n",
        "\n",
        "            # Calculate rouge scores for each prediction and corresponding target\n",
        "            for pred, target in zip(preds, targets):\n",
        "                score = scorer.score(target, pred)\n",
        "                scores.append(score)\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(targets)\n",
        "\n",
        "    # Compute the average ROUGE scores for the entire validation set\n",
        "    avg_scores = {\n",
        "        \"rouge1\": np.mean([score[\"rouge1\"].fmeasure for score in scores]),\n",
        "        \"rouge2\": np.mean([score[\"rouge2\"].fmeasure for score in scores]),\n",
        "        \"rougeL\": np.mean([score[\"rougeL\"].fmeasure for score in scores]),\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Average ROUGE scores: {avg_scores}\")\n",
        "\n",
        "    return predictions, actuals\n",
        "\n",
        "\n",
        "# T5 training main function\n",
        "def T5Trainer(dataframe, source_text, target_text):\n",
        "    # Set random seeds and deterministic pytorch for reproducibility\n",
        "    torch.manual_seed(model_params[\"SEED\"])\n",
        "    np.random.seed(model_params[\"SEED\"])\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    logger.info(f\"Reading data...\")\n",
        "    # Importing the raw dataset\n",
        "    dataframe = dataframe[[source_text, target_text]]\n",
        "\n",
        "    # Creation of Dataset and Dataloader\n",
        "    # 80% of the data will be used for training and the rest for validation\n",
        "    train_size = model_params[\"TRAINING_VALIDATION_SPLIT\"]\n",
        "    train_dataset = dataframe.sample(frac=train_size, random_state=model_params[\"SEED\"])\n",
        "    val_dataset = dataframe.drop(train_dataset.index).reset_index(drop=True)\n",
        "    train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "    logger.info(f\"FULL Dataset: {dataframe.shape}\")\n",
        "    logger.info(f\"TRAIN Dataset: {train_dataset.shape}\")\n",
        "    logger.info(f\"VALIDATION Dataset: {val_dataset.shape}\")\n",
        "\n",
        "    # Creating the Training and Validation dataset for further creation of data loader\n",
        "    training_set = CustomDataset(\n",
        "        train_dataset,\n",
        "        tokenizer,\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        source_text,\n",
        "        target_text,\n",
        "    )\n",
        "    val_set = CustomDataset(\n",
        "        val_dataset,\n",
        "        tokenizer,\n",
        "        model_params[\"MAX_SOURCE_TEXT_LENGTH\"],\n",
        "        model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        source_text,\n",
        "        target_text,\n",
        "    )\n",
        "\n",
        "    # Defining the parameters for creation of data loaders\n",
        "    train_params = {\n",
        "        \"batch_size\": model_params[\"TRAIN_BATCH_SIZE\"],\n",
        "        \"shuffle\": True,\n",
        "        \"num_workers\": 0,\n",
        "    }\n",
        "    val_params = {\n",
        "        \"batch_size\": model_params[\"VALID_BATCH_SIZE\"],\n",
        "        \"shuffle\": False,\n",
        "        \"num_workers\": 0,\n",
        "    }\n",
        "\n",
        "    # Creation of data loaders for testing and validation - this will be used down for training and validation stage for the model\n",
        "    training_loader = DataLoader(training_set, **train_params)\n",
        "    val_loader = DataLoader(val_set, **val_params)\n",
        "\n",
        "    # Defining the optimizer that will be used to tune the weights of the network in the training session\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        params=[p for p in model.parameters() if p.requires_grad],\n",
        "        lr=model_params[\"LEARNING_RATE\"],\n",
        "        eps=model_params[\"ADAM_EPSILON\"],\n",
        "        weight_decay=model_params[\"WEIGHT_DECAY\"],\n",
        "    )\n",
        "\n",
        "    # Define the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=model_params[\"WARMUP_STEPS\"],\n",
        "        num_training_steps=model_params[\"TRAIN_EPOCHS\"]\n",
        "        * len(training_loader)\n",
        "        // model_params[\"GRADIENT_ACCUMULATION_STEPS\"],\n",
        "    )\n",
        "\n",
        "    # Training loop\n",
        "    logger.info(f\"Initiating fine tuning of {model_params['MODEL']}...\")\n",
        "    # Table logger for training statistics\n",
        "    with refresher:\n",
        "        for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n",
        "            train(\n",
        "                epoch, tokenizer, model, device, training_loader, optimizer, scheduler\n",
        "            )\n",
        "            pass\n",
        "\n",
        "    logger.info(f\"Saving fine-tuned  to {model_output_directory} ...\")\n",
        "    # Saving the model after training\n",
        "    model.save_pretrained(model_output_directory)\n",
        "    tokenizer.save_pretrained(model_output_directory)\n",
        "    logger.info(f\"Fine-tuned model successfully saved to: {model_output_directory}\")\n",
        "\n",
        "    # Evaluating validation dataset\n",
        "    logger.info(f\"Initiating validation...\")\n",
        "    validation_filepath = os.path.join(model_output_directory, \"predictions.csv\")\n",
        "    for epoch in range(model_params[\"VAL_EPOCHS\"]):\n",
        "        predictions, actuals = validate(tokenizer, model, device, val_loader)\n",
        "        final_df = pd.DataFrame({\"Generated Text\": predictions, \"Actual Text\": actuals})\n",
        "        final_df.to_csv(validation_filepath)\n",
        "    logger.success(\n",
        "        f\"Model validation completed, saving results to {validation_filepath}\"\n",
        "    )\n",
        "    logger.info(f\"Validation data successfully saved to: {validation_filepath}\")\n",
        "\n",
        "\n",
        "# In case of interrupt, save model and exit\n",
        "def save_and_exit(signal, _):\n",
        "    logger.warning(f\"Received signal {signal}, stopping script and saving model...\")\n",
        "    model.save_pretrained(model_output_directory)\n",
        "    tokenizer.save_pretrained(model_output_directory)\n",
        "    logger.success(\"Model saved. Shutting down...\")\n",
        "    return 0\n",
        "\n",
        "\n",
        "# Attach the SIGINT signal (generated by Ctrl+C) to the handler\n",
        "signal.signal(signal.SIGINT, save_and_exit)\n",
        "\n",
        "# Run training function on the T5 model using data set and training parameters\n",
        "T5Trainer(dataframe=data, source_text=\"input\", target_text=\"output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Instantiate Target Model for Manual Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manual testing target model\n",
        "\n",
        "input_model_directory_path = \"../models/t5-tiny_bullet-forge/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Fine Tuned Model Manual Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manual test scripts\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "from scripts.files import load_jsonl_data\n",
        "from scripts.bullet_patterns import BULLET_PROMPT_PREFIX\n",
        "\n",
        "# Model generation parameter control object\n",
        "model_params = {\n",
        "    # Name of the pre-trained model that will be fine-tuned\n",
        "    \"MODEL\": f\"{input_model_directory_path}\",\n",
        "    # Maximum number of tokens from source text that model accepts\n",
        "    \"MAX_SOURCE_TEXT_LENGTH\": max_input_token_length,\n",
        "    # Maximum number of tokens from target text that model generates\n",
        "    \"MAX_TARGET_TEXT_LENGTH\": max_output_token_length,\n",
        "    # Number of alternative sequences generated at each step\n",
        "    # More beams improve results, but increase computation\n",
        "    \"NUM_BEAMS\": number_of_beams,\n",
        "    # Scales logits before soft-max to control randomness\n",
        "    # Lower values (~0) make output more deterministic\n",
        "    \"TEMPERATURE\": 0.9,\n",
        "    # Limits generated tokens to top K probabilities\n",
        "    # Reduces chances of rare word predictions\n",
        "    \"TOP_K\": 50,\n",
        "    # Applies nucleus sampling, limiting token selection to a cumulative probability\n",
        "    # Creates a balance between randomness and determinism\n",
        "    \"TOP_P\": 0.90,\n",
        "}\n",
        "\n",
        "\n",
        "# Load the T5 model\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\n",
        "    model_params[\"MODEL\"], model_max_length=model_params[\"MAX_SOURCE_TEXT_LENGTH\"]\n",
        ")\n",
        "\n",
        "# Load the data from the manual test file\n",
        "data = load_jsonl_data(\n",
        "    \"../data/training/manual_test_set.jsonl\", BULLET_PROMPT_PREFIX, isDataFrame=False\n",
        ")\n",
        "for line in data:\n",
        "    # Preprocess input\n",
        "    input_text = line[\"input\"]\n",
        "    expected_summary = line[\"output\"]\n",
        "\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        input_text, return_tensors=\"pt\", truncation=True, max_length=512\n",
        "    )\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=model_params[\"MAX_TARGET_TEXT_LENGTH\"],\n",
        "        num_beams=model_params[\"NUM_BEAMS\"],\n",
        "        temperature=model_params[\"TEMPERATURE\"],\n",
        "        top_k=model_params[\"TOP_K\"],\n",
        "        top_p=model_params[\"TOP_P\"],\n",
        "        early_stopping=True,\n",
        "    )\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"> INPUT TEXT: {input_text}\")\n",
        "    print(f\"\\t> EXPECTED SUMMARY: {expected_summary}\")\n",
        "    print(f\"\\t> GENERATED SUMMARY: {summary}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM+sqU2Hgca8RM/Wjv+9kvQ",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "T5 Fine tuning with PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
