{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Model Fine-tuning\n",
    "\n",
    "This notebook is used for fine-tuning the T5 base model. Please refer to the `README.md` within the parent `forge/` directory for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read, Tokenize and Encode Data\n",
    "\n",
    "The block below reads data to memory and performs tokenization on all IO for the fine tuning process. \n",
    "\n",
    "- TRAINING_FILE: The name of the JSONL file, from the `data/training` directory\n",
    "- MAXIMUM_SIZE: The maximum size of the data you want to read to memory, where `0` extracts all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-09 21:08:51.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mSample of the tokenized and encoded data: {'input_ids': tensor([[282,   8, 262,  ...,   0,   0,   0]]), 'labels': tensor([[  3,  18, 262,  ...,   0,   0,   0]])}\u001b[0m\n",
      "\u001b[32m2023-07-09 21:08:51.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mTotal count of tokenized and encoded data: 100\u001b[0m\n",
      "\u001b[32m2023-07-09 21:08:51.006\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m32\u001b[0m - \u001b[32m\u001b[1mThe data has been tokenized and encoded into memory!\u001b[0m\n",
      "\u001b[32m2023-07-09 21:08:51.007\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m33\u001b[0m - \u001b[33m\u001b[1mThis tokenized and encoded data is only temporarily stored in the Jupyter Notebook instance.\u001b[0m\n",
      "\u001b[32m2023-07-09 21:08:51.009\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m34\u001b[0m - \u001b[33m\u001b[1mFailing to save the data to file wil result in loss during restart or clearing of outputs.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from loguru import logger\n",
    "from scripts.utils.file_utils import jsonl_read\n",
    "from scripts.prepare_training import tokenize_and_encode\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Read in the training data JSONL file\n",
    "    TRAINING_FILE = input(\"Enter the JSONL filename: \")\n",
    "    MAXIMUM_SIZE = input(\"Enter a maximum data read size: \")\n",
    "    training_file_path = f\"../data/training/{TRAINING_FILE}\"\n",
    "    data = await jsonl_read(training_file_path, int(MAXIMUM_SIZE))\n",
    "    if data == []:\n",
    "        logger.error(\n",
    "            f\"An error occurred during the reading of JSONL file: {training_file_path}\"\n",
    "        )\n",
    "        exit(1)\n",
    "\n",
    "    # Tokenize and encode each IO pair\n",
    "    return await tokenize_and_encode(data)\n",
    "\n",
    "\n",
    "# Run the async events\n",
    "def run_asyncio_loop():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return loop.run_until_complete(main())\n",
    "\n",
    "\n",
    "# Enable nested event loops\n",
    "nest_asyncio.apply()\n",
    "prepared_data = run_asyncio_loop()\n",
    "\n",
    "logger.info(f\"Sample of the tokenized and encoded data: {prepared_data[0]}\")\n",
    "logger.info(f\"Total count of tokenized and encoded data: {len(prepared_data)}\")\n",
    "logger.success(f\"The data has been tokenized and encoded into memory!\")\n",
    "logger.warning(\n",
    "    f\"This tokenized and encoded data is only temporarily stored in the Jupyter Notebook instance.\"\n",
    ")\n",
    "logger.warning(\n",
    "    f\"Failing to save the data to file wil result in loss during restart or clearing of outputs.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\u001b[32m2023-07-09 21:11:57.826\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m61\u001b[0m - \u001b[31m\u001b[1mAn error occurred during training: too many values to unpack (expected 2)\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/...\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x10ee5df80>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x10bcf5350>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 728, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x10ee68220>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x10ee77a50>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x10bcf5350>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function _patch_loop.<locals>.run_forever at 0x12d2ff560>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x10ee77a50>\n",
      "\n",
      "  File \"\u001b[32m/usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/\u001b[0m\u001b[32m\u001b[1mbase_events.py\u001b[0m\", line \u001b[33m607\u001b[0m, in \u001b[35mrun_forever\u001b[0m\n",
      "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_run_once\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<function _patch_loop.<locals>._run_once at 0x12d2ff6a0>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<_UnixSelectorEventLoop running=True closed=False debug=False>\u001b[0m\n",
      "\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/nest_asyncio.py\", line 120, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x10cc0f1a0>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...dd0>, ...],))>)>\n",
      "\n",
      "  File \"\u001b[32m/usr/local/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/\u001b[0m\u001b[32m\u001b[1mevents.py\u001b[0m\", line \u001b[33m80\u001b[0m, in \u001b[35m_run\u001b[0m\n",
      "    \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_context\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mrun\u001b[0m\u001b[1m(\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_callback\u001b[0m\u001b[1m,\u001b[0m \u001b[35m\u001b[1m*\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_args\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m│    │            │    │           │    └ \u001b[0m\u001b[36m\u001b[1m<member '_args' of 'Handle' objects>\u001b[0m\n",
      "    \u001b[36m│    │            │    │           └ \u001b[0m\u001b[36m\u001b[1m<Handle Task.task_wakeup(<Future finis...dd0>, ...],))>)>\u001b[0m\n",
      "    \u001b[36m│    │            │    └ \u001b[0m\u001b[36m\u001b[1m<member '_callback' of 'Handle' objects>\u001b[0m\n",
      "    \u001b[36m│    │            └ \u001b[0m\u001b[36m\u001b[1m<Handle Task.task_wakeup(<Future finis...dd0>, ...],))>)>\u001b[0m\n",
      "    \u001b[36m│    └ \u001b[0m\u001b[36m\u001b[1m<member '_context' of 'Handle' objects>\u001b[0m\n",
      "    \u001b[36m└ \u001b[0m\u001b[36m\u001b[1m<Handle Task.task_wakeup(<Future finis...dd0>, ...],))>)>\u001b[0m\n",
      "\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "          │    └ <function Kernel.process_one at 0x10e81d9e0>\n",
      "          └ <ipykernel.ipkernel.IPythonKernel object at 0x10ee750d0>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "          │         └ ([<zmq.sugar.frame.Frame object at 0x10ecc6ed0>, <zmq.sugar.frame.Frame object at 0x10ecc6e10>, <zmq.sugar.frame.Frame object...\n",
      "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x10ee750d0>>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "          └ <coroutine object Kernel.execute_request at 0x10ebebcc0>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "                          └ <coroutine object IPythonKernel.do_execute at 0x10ebf6440>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "          │     └ <function ZMQInteractiveShell.run_cell at 0x10ee43380>\n",
      "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10eebfb90>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "                             │       └ {'store_history': True, 'silent': False, 'cell_id': 'vscode-notebook-cell:/Users/justin/Documents/Code/personal/smarter-bulle...\n",
      "                             └ ('import torch\\nfrom torch.utils.data import DataLoader, TensorDataset\\nfrom transformers import (\\n    T5ForConditionalGener...\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "             │    └ <function InteractiveShell._run_cell at 0x10dc59da0>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10eebfb90>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "             │      └ <coroutine object InteractiveShell.run_cell_async at 0x10ec9df20>\n",
      "             └ <function _pseudo_sync_runner at 0x10dc48f40>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    │    └ <method 'send' of 'coroutine' objects>\n",
      "    └ <coroutine object InteractiveShell.run_cell_async at 0x10ec9df20>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                       │    │             │        │     └ '/var/folders/f1/_vqvbs517hn1khv6hl8jvy1w0000gn/T/ipykernel_67324/866258464.py'\n",
      "                       │    │             │        └ [<ast.Import object at 0x12c054670>, <ast.ImportFrom object at 0x12c0543a0>, <ast.ImportFrom object at 0x12c054460>, <ast.Imp...\n",
      "                       │    │             └ <ast.Module object at 0x12c054af0>\n",
      "                       │    └ <function InteractiveShell.run_ast_nodes at 0x10dc5a0c0>\n",
      "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10eebfb90>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "             │    │        │     │              └ False\n",
      "             │    │        │     └ <ExecutionResult object at 12d332410, execution_count=4 error_before_exec=None error_in_exec=None info=<ExecutionInfo object ...\n",
      "             │    │        └ <code object <module> at 0x7fe7fc4542e0, file \"/var/folders/f1/_vqvbs517hn1khv6hl8jvy1w0000gn/T/ipykernel_67324/866258464.py\"...\n",
      "             │    └ <function InteractiveShell.run_code at 0x10dc5a160>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10eebfb90>\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "         │         │    │               │    └ {'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, ...\n",
      "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10eebfb90>\n",
      "         │         │    └ <property object at 0x10dc45f80>\n",
      "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10eebfb90>\n",
      "         └ <code object <module> at 0x7fe7fc4542e0, file \"/var/folders/f1/_vqvbs517hn1khv6hl8jvy1w0000gn/T/ipykernel_67324/866258464.py\"...\n",
      "\n",
      "> File \"\u001b[32m/var/folders/f1/_vqvbs517hn1khv6hl8jvy1w0000gn/T/ipykernel_67324/\u001b[0m\u001b[32m\u001b[1m866258464.py\u001b[0m\", line \u001b[33m48\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1moutputs\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mmodel\u001b[0m\u001b[1m(\u001b[0m\u001b[1minput_ids\u001b[0m\u001b[35m\u001b[1m=\u001b[0m\u001b[1minput_ids\u001b[0m\u001b[1m,\u001b[0m \u001b[1mlabels\u001b[0m\u001b[35m\u001b[1m=\u001b[0m\u001b[1mlabels\u001b[0m\u001b[1m)\u001b[0m\n",
      "    \u001b[36m          │               │                 └ \u001b[0m\u001b[36m\u001b[1mtensor([[[    3,    18,   262,  ...,     0,     0,     0]],\u001b[0m\n",
      "    \u001b[36m          │               │                   \u001b[0m\u001b[36m\u001b[1m\u001b[0m\n",
      "    \u001b[36m          │               │                   \u001b[0m\u001b[36m\u001b[1m        [[    3,    18, 29169,  ...,     0,     0,     0]],\u001b[0m\n",
      "    \u001b[36m          │               │                   \u001b[0m\u001b[36m\u001b[1m\u001b[0m\n",
      "    \u001b[36m          │               │                   \u001b[0m\u001b[36m\u001b[1m   ...\u001b[0m\n",
      "    \u001b[36m          │               └ \u001b[0m\u001b[36m\u001b[1mtensor([[[  282,     8,   262,  ...,     0,     0,     0]],\u001b[0m\n",
      "    \u001b[36m          │                 \u001b[0m\u001b[36m\u001b[1m\u001b[0m\n",
      "    \u001b[36m          │                 \u001b[0m\u001b[36m\u001b[1m        [[   27,   808,  1567,  ...,     0,     0,     0]],\u001b[0m\n",
      "    \u001b[36m          │                 \u001b[0m\u001b[36m\u001b[1m\u001b[0m\n",
      "    \u001b[36m          │                 \u001b[0m\u001b[36m\u001b[1m   ...\u001b[0m\n",
      "    \u001b[36m          └ \u001b[0m\u001b[36m\u001b[1mT5ForConditionalGeneration(\u001b[0m\n",
      "    \u001b[36m            \u001b[0m\u001b[36m\u001b[1m  (shared): Embedding(32128, 768)\u001b[0m\n",
      "    \u001b[36m            \u001b[0m\u001b[36m\u001b[1m  (encoder): T5Stack(\u001b[0m\n",
      "    \u001b[36m            \u001b[0m\u001b[36m\u001b[1m    (embed_tokens): Embedding(32128, 768)...\u001b[0m\n",
      "\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           │             │       └ {'input_ids': tensor([[[  282,     8,   262,  ...,     0,     0,     0]],\n",
      "           │             │         \n",
      "           │             │                 [[   27,   808,  1567,  ...,     0,     0,...\n",
      "           │             └ ()\n",
      "           └ <bound method T5ForConditionalGeneration.forward of T5ForConditionalGeneration(\n",
      "               (shared): Embedding(32128, 768)\n",
      "               (encoder)...\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py\", line 1683, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      └ T5ForConditionalGeneration(\n",
      "                          (shared): Embedding(32128, 768)\n",
      "                          (encoder): T5Stack(\n",
      "                            (embed_tokens): Embedding(32128, 768)...\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           │             │       └ {'input_ids': tensor([[[  282,     8,   262,  ...,     0,     0,     0]],\n",
      "           │             │         \n",
      "           │             │                 [[   27,   808,  1567,  ...,     0,     0,...\n",
      "           │             └ ()\n",
      "           └ <bound method T5Stack.forward of T5Stack(\n",
      "               (embed_tokens): Embedding(32128, 768)\n",
      "               (block): ModuleList(\n",
      "                 (0): T5Block(\n",
      "               ...\n",
      "  File \"/Users/justin/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py\", line 990, in forward\n",
      "    batch_size, seq_length = input_shape\n",
      "                             └ torch.Size([16, 1, 1024])\n",
      "\n",
      "\u001b[31m\u001b[1mValueError\u001b[0m:\u001b[1m too many values to unpack (expected 2)\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m labels \u001b[39m=\u001b[39m batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     46\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 48\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39;49minput_ids, labels\u001b[39m=\u001b[39;49mlabels)\n\u001b[1;32m     50\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     51\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1683\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[39m# Encode if needed (training, first prediction pass)\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1682\u001b[0m     \u001b[39m# Convert encoder inputs in embeddings if needed\u001b[39;00m\n\u001b[0;32m-> 1683\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1684\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m   1685\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1686\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1687\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1688\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1689\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1690\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1691\u001b[0m     )\n\u001b[1;32m   1692\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n\u001b[1;32m   1693\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1694\u001b[0m         last_hidden_state\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m0\u001b[39m],\n\u001b[1;32m   1695\u001b[0m         hidden_states\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1696\u001b[0m         attentions\u001b[39m=\u001b[39mencoder_outputs[\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(encoder_outputs) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1697\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Code/personal/smarter-bullets/.venv/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:990\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    988\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens(input_ids)\n\u001b[0;32m--> 990\u001b[0m batch_size, seq_length \u001b[39m=\u001b[39m input_shape\n\u001b[1;32m    992\u001b[0m \u001b[39m# required mask seq length can be calculated via length of past\u001b[39;00m\n\u001b[1;32m    993\u001b[0m mask_seq_length \u001b[39m=\u001b[39m past_key_values[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m seq_length \u001b[39mif\u001b[39;00m past_key_values \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m seq_length\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from loguru import logger\n",
    "\n",
    "# Load the pre-trained T5 model and tokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "\n",
    "# Configure the training parameters\n",
    "epochs = 3\n",
    "learning_rate = 2e-5\n",
    "warmup_steps = 1000\n",
    "total_steps = len(prepared_data) * epochs\n",
    "\n",
    "# Prepare the input tensors\n",
    "input_ids = torch.stack([item[\"input_ids\"] for item in prepared_data])\n",
    "labels = torch.stack([item[\"labels\"] for item in prepared_data])\n",
    "\n",
    "# Create a dataset and data loader\n",
    "dataset = TensorDataset(input_ids, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "# Define the optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Start the training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        logger.info(f\"Epoch {epoch + 1} - Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An error occurred during training: {e}\")\n",
    "    raise\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "try:\n",
    "    model.save_pretrained(\"../models/t5/trained/model-100\")\n",
    "    logger.success(\"Successfully saved t5-base model!\")\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An error occurred while saving the model: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
