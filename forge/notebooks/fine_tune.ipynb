{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Model Fine-tuning\n",
    "\n",
    "This notebook is used for fine-tuning the T5 base model. Please refer to the `README.md` within the parent `forge/` directory for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read and Tokenize Data\n",
    "\n",
    "The block below reads data to memory and performs tokenization on all IO for the fine tuning process. \n",
    "\n",
    "- TRAINING_FILE: The name of the JSONL file, from the `data/training` directory\n",
    "- MAXIMUM_SIZE: The maximum size of the data you want to read to memory, where `0` extracts all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': tensor([[  27, 5153,    8,  ...,    0,    0,    0]]), 'labels': tensor([[ 3, 18, 71,  ...,  0,  0,  0]])}, {'input_ids': tensor([[ 282,    8, 4564,  ...,    0,    0,    0]]), 'labels': tensor([[ 3, 18,  3,  ...,  0,  0,  0]])}, {'input_ids': tensor([[   27, 11197,  1361,  ...,     0,     0,     0]]), 'labels': tensor([[   3,   18, 9506,  ...,    0,    0,    0]])}, {'input_ids': tensor([[  27, 4468,    3,  ...,    0,    0,    0]]), 'labels': tensor([[   3,   18, 1193,  ...,    0,    0,    0]])}, {'input_ids': tensor([[  282,     8, 14640,  ...,     0,     0,     0]]), 'labels': tensor([[  3,  18, 180,  ...,   0,   0,   0]])}, {'input_ids': tensor([[  27, 4252,  192,  ...,    0,    0,    0]]), 'labels': tensor([[  3,  18, 332,  ...,   0,   0,   0]])}, {'input_ids': tensor([[282,   3,   9,  ...,   0,   0,   0]]), 'labels': tensor([[    3,    18, 16736,  ...,     0,     0,     0]])}, {'input_ids': tensor([[  86,   82, 1075,  ...,    0,    0,    0]]), 'labels': tensor([[  3,  18, 454,  ...,   0,   0,   0]])}, {'input_ids': tensor([[   3, 2092, 6411,  ...,    0,    0,    0]]), 'labels': tensor([[    3,    18, 23736,  ...,     0,     0,     0]])}, {'input_ids': tensor([[  27,  937, 3435,  ...,    0,    0,    0]]), 'labels': tensor([[ 3, 18,  3,  ...,  0,  0,  0]])}, {'input_ids': tensor([[   27,     3, 26474,  ...,     0,     0,     0]]), 'labels': tensor([[ 3, 18,  3,  ...,  0,  0,  0]])}, {'input_ids': tensor([[282,   3,   9,  ...,   0,   0,   0]]), 'labels': tensor([[   3,   18, 8662,  ...,    0,    0,    0]])}, {'input_ids': tensor([[   27, 11752,    16,  ...,     0,     0,     0]]), 'labels': tensor([[ 3, 18,  3,  ...,  0,  0,  0]])}, {'input_ids': tensor([[ 282,    8, 2488,  ...,    0,    0,    0]]), 'labels': tensor([[  3,  18, 312,  ...,   0,   0,   0]])}, {'input_ids': tensor([[  27, 4468,  507,  ...,    0,    0,    0]]), 'labels': tensor([[  3,  18, 707,  ...,   0,   0,   0]])}, {'input_ids': tensor([[ 282,    8, 2488,  ...,    0,    0,    0]]), 'labels': tensor([[  3,  18, 312,  ...,   0,   0,   0]])}, {'input_ids': tensor([[  86,   82, 1075,  ...,    0,    0,    0]]), 'labels': tensor([[   3,   18, 2263,  ...,    0,    0,    0]])}, {'input_ids': tensor([[   27,     3, 16466,  ...,     0,     0,     0]]), 'labels': tensor([[   3,   18, 5331,  ...,    0,    0,    0]])}, {'input_ids': tensor([[  27, 2425, 2641,  ...,    0,    0,    0]]), 'labels': tensor([[  3,  18, 374,  ...,   0,   0,   0]])}, {'input_ids': tensor([[282,   3,   9,  ...,   0,   0,   0]]), 'labels': tensor([[   3,   18, 1266,  ...,    0,    0,    0]])}, {'input_ids': tensor([[  27, 2127, 7505,  ...,    0,    0,    0]]), 'labels': tensor([[    3,    18, 25275,  ...,     0,     0,     0]])}, {'input_ids': tensor([[   27, 12996,     3,  ...,     0,     0,     0]]), 'labels': tensor([[ 3, 18, 27,  ...,  0,  0,  0]])}, {'input_ids': tensor([[   27, 18149,  5388,  ...,     0,     0,     0]]), 'labels': tensor([[    3,    18, 30543,  ...,     0,     0,     0]])}, {'input_ids': tensor([[282,   3,   9,  ...,   0,   0,   0]]), 'labels': tensor([[   3,   18, 1485,  ...,    0,    0,    0]])}, {'input_ids': tensor([[ 27, 876,  46,  ...,   0,   0,   0]]), 'labels': tensor([[ 3, 18,  3,  ...,  0,  0,  0]])}, {'input_ids': tensor([[282,   3,   9,  ...,   0,   0,   0]]), 'labels': tensor([[ 3, 18,  3,  ...,  0,  0,  0]])}, {'input_ids': tensor([[  27, 2925,   82,  ...,    0,    0,    0]]), 'labels': tensor([[    3,    18, 13270,  ...,     0,     0,     0]])}, {'input_ids': tensor([[  27, 3250, 2900,  ...,    0,    0,    0]]), 'labels': tensor([[   3,   18, 6130,  ...,    0,    0,    0]])}, {'input_ids': tensor([[   27, 11752,     8,  ...,     0,     0,     0]]), 'labels': tensor([[ 3, 18,  3,  ...,  0,  0,  0]])}, {'input_ids': tensor([[  27, 4717,   30,  ...,    0,    0,    0]]), 'labels': tensor([[   3,   18, 2415,  ...,    0,    0,    0]])}]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from loguru import logger\n",
    "from scripts.utils.file_utils import jsonl_read\n",
    "from scripts.prepare_training import read_and_encode\n",
    "\n",
    "async def main():\n",
    "    # Read in the training data JSONL file\n",
    "    TRAINING_FILE = input(\"Enter the JSONL filename: \")\n",
    "    MAXIMUM_SIZE = input(\"Enter a maximum data read size: \")\n",
    "    training_file_path = f\"../data/training/{TRAINING_FILE}\"\n",
    "    data = await jsonl_read(training_file_path, int(MAXIMUM_SIZE))\n",
    "    if data == []:\n",
    "        logger.error(f\"An error occurred during the reading of JSONL file: {training_file_path}\")\n",
    "        exit(1)\n",
    "    return await read_and_encode(data)\n",
    "\n",
    "\n",
    "def run_asyncio_loop():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return loop.run_until_complete(main())\n",
    "\n",
    "\n",
    "# Enable nested event loops in Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "prepared_data = run_asyncio_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prepared_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
