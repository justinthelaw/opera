{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bullet Forge Training Data\n",
    "\n",
    "This notebook is used for forming the JSONL files used by `fine_tune.ipynb` to fine-tune the base model. The goal is to use `scrape.py` to scrape for open-source bullets at a particular URL and use those as completions. Then, those completions have prompts that are a combination of ChatGPT generated long-form paragraphs from those bullets, prepended with the bullet formatting prompt."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run the Bullet Scraper\n",
    "\n",
    "Please see the `scripts/` directory for more details. Please be warned that the scraper, although parallelized, may take a long time to run through all of the identified bullet repositories.\n",
    "\n",
    "The block below runs the scraper on all the easily scrape-able websites located within the `resources/websites.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths=[]\n",
    "\n",
    "with open('resources/websites.txt', 'r') as file:\n",
    "    urls = file.readlines()\n",
    "\n",
    "for url in urls:\n",
    "    url = url.strip()\n",
    "    filename = url[url.index(\"www.\") + 4:url.index(\".com\")]\n",
    "    filepath = f\"../data/raw/{filename}.txt\"\n",
    "    !python3 scripts/scrape.py \"{url}\" \"{filepath}\"\n",
    "    file_paths.append(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below is **_OPTIONAL_**. It allows you to run the scraper on websites one at a time. It requires the following input:\n",
    "- BASE_URL: The base URL including the protocol.\n",
    "\n",
    "This is useful for the website(s) below, where there is a hard-coded records limit.\n",
    "\n",
    "- https://www.afeprbullets.com/results.php?Submit5=Search&strength=Positive&rec=8124\n",
    "\n",
    "**_IMPORTANT NOTE_**: once success has been logged, wait 30 more seconds and stop the script, otherwise you will be waiting a really long time for it to shutdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = input(\"Enter a base url to scrape from\")\n",
    "\n",
    "filename = BASE_URL[BASE_URL.index(\"www.\") + 4:BASE_URL.index(\".com\")]\n",
    "filepath = f\"../data/raw/{filename}.txt\"\n",
    "!python3 scripts/scrape.py \"{BASE_URL}\" \"{filepath}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean the Scraped Data\n",
    "\n",
    "The scraped data requires some extra cleaning. This removes bullets that are clearly way too long or short, and provides proper spacing and formatting to bullets that do not follow the standard bullet format.\n",
    "\n",
    "- DIRTY_FILE: The name of the text file you want cleaned, from the `data/raw` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRTY_FILE = input(\"Enter a filename to clean\")\n",
    "\n",
    "dirty_file_path = f\"../data/raw/{DIRTY_FILE}\"\n",
    "\n",
    "!python3 scripts/clean.py \"{dirty_file_path}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Consolidate the Cleaned Data\n",
    "\n",
    "Consolidate all clean, scraped bullet website outputs from the `data/raw` directory into one JSONL file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = \"../data/raw/\"\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_paths.append(file_path)\n",
    "\n",
    "file_paths_string = \" \".join(file_paths)\n",
    "\n",
    "!python3 scripts/consolidate.py {file_paths_string}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
